#!/bin/bash
# åˆ‡æ¢åˆ° Time-LLM ç›®å½•
cd "$(dirname "$0")/.." || exit 1
# === ç¼“å­˜è·¯å¾„é…ç½® ===
export HF_HOME="/home/nl/disk_8T/lys/cache/huggingface"
export HUGGINGFACE_HUB_CACHE="$HF_HOME/hub"
export TRANSFORMERS_CACHE="$HF_HOME/transformers"
export TORCH_HOME="$HF_HOME/torch"
export TMPDIR="/tmp"
export HF_ENDPOINT="https://hf-mirror.com"  # ä½¿ç”¨é•œåƒç«™
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# ğŸ”¥ ä¿®å¤1ï¼šå¼ºåˆ¶é™åˆ¶ CPU çº¿ç¨‹æ•°ï¼ˆè§£å†³ 11 ä¸ªè¿›ç¨‹å‡è±¡å’Œ CPU æŠ¢å ï¼‰
export OMP_NUM_THREADS=4
export MKL_NUM_THREADS=4
export TORCH_NUM_THREADS=4
export VECLIB_MAXIMUM_THREADS=4
export NUMEXPR_NUM_THREADS=4

# åˆ›å»ºç¼“å­˜ç›®å½•
mkdir -p "$HF_HOME" "$HUGGINGFACE_HUB_CACHE" "$TRANSFORMERS_CACHE" "$TORCH_HOME" "$TMPDIR"

# === æ¨¡å‹å‚æ•° ===
model_name=TimeLLM
train_epochs=15
learning_rate=0.01
gpt2_layers=6

# === è®­ç»ƒé…ç½® ===
master_port=0
num_process=1  # ä½¿ç”¨å•ä¸ªGPU
batch_size=8
d_model=32
d_ff=128

comment='TimeLLM-ETTh1-GPT2'

# === å› æœæ¨¡å—å‚æ•° ===
use_causal="--use_causal"
use_amp="--use_amp" 
causal_cache_dir="./causal_results"
causal_tau_max=5
causal_pc_alpha=0.01
causal_top_k=5

use_causal_loss="--use_causal_loss"
causal_loss_weight=0.1


accelerate launch --mixed_precision fp16 --num_processes 1 --num_machines 1 run_main.py \
  --task_name long_term_forecast \
  --is_training 1 \
  --root_path ./dataset/ETT-small/ \
  --data_path ETTh1.csv \
  --model_id ETTh1_512_96 \
  --model $model_name \
  --data ETTh1 \
  --features M \
  --seq_len 512 \
  --label_len 48 \
  --pred_len 96 \
  --factor 3 \
  --enc_in 7 \
  --dec_in 7 \
  --c_out 7 \
  --des 'Exp' \
  --itr 1 \
  --d_model $d_model \
  --d_ff $d_ff \
  --batch_size $batch_size \
  --learning_rate $learning_rate \
  --llm_model GPT2 \
  --llm_dim 768 \
  --llm_layers $gpt2_layers \
  --llm_cache_dir $HF_HOME \
  --train_epochs $train_epochs \
  --model_comment $comment \
  --num_workers 0 \
  $use_causal \
  $use_causal_loss \
  $use_amp \
  --causal_cache_dir $causal_cache_dir \
  --causal_tau_max $causal_tau_max \
  --causal_pc_alpha $causal_pc_alpha \
  --causal_top_k $causal_top_k \
  --causal_loss_weight $causal_loss_weight
  

echo ""
echo "=========================================="
echo "All experiments completed!"
echo "Results saved in ./checkpoints/"
echo "=========================================="
